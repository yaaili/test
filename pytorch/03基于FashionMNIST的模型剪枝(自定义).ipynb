{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "基于FashionMNIST的模型剪枝(自定义).ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMcZ3/DH7eEeqzektX1SNlZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaaili/test/blob/master/pytorch/03%E5%9F%BA%E4%BA%8EFashionMNIST%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D(%E8%87%AA%E5%AE%9A%E4%B9%89).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMYVMt3dzqsh",
        "colab_type": "text"
      },
      "source": [
        "# 1 导入相关包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyC_ni8Iznyr",
        "colab_type": "code",
        "outputId": "33545159-c52a-46ba-e61a-3b40d67c98e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 导入相关包\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/pytorch深度学习\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARQLeaxVuFSZ",
        "colab_type": "code",
        "outputId": "b042bfd2-f462-498a-b80f-5d5c1ce6507f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "print(torch.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x5Gfc79odoB",
        "colab_type": "text"
      },
      "source": [
        "# 2 构建网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er6HzolpO3xB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def to_var(x, requires_grad=False):\n",
        "    \"\"\"\n",
        "    Automatically choose cpu or cuda\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return x.clone().detach().requires_grad_(requires_grad)\n",
        "\n",
        "\n",
        "def weight_prune(model, pruning_perc):\n",
        "    '''\n",
        "    Prune pruning_perc % weights layer-wise\n",
        "    '''\n",
        "    threshold_list = []\n",
        "    line = np.array([],dtype=np.float32)\n",
        "    for p in model.parameters():\n",
        "        if len(p.data.size()) != 1:  # bias\n",
        "            if len(p.data.size()) != 4:\n",
        "                weight = p.cpu().data.abs().numpy().flatten()\n",
        "                line = np.hstack((line,weight))\n",
        "    threshold = np.percentile(line, pruning_perc)\n",
        "\n",
        "    # generate mask\n",
        "    masks = []\n",
        "    for p in model.parameters():\n",
        "        if len(p.data.size()) != 1:\n",
        "            if len(p.data.size()) != 4:\n",
        "                pruned_inds = p.data.abs() > threshold\n",
        "                masks.append(pruned_inds.float())\n",
        "    return masks\n",
        "\n",
        "\n",
        "\"\"\"Reference https://github.com/zepx/pytorch-weight-prune/\"\"\"\n",
        "\n",
        "\n",
        "def prune_rate(model, verbose=False):\n",
        "    \"\"\"\n",
        "    Print out prune rate for each layer and the whole network\n",
        "    \"\"\"\n",
        "    total_nb_param = 0\n",
        "    nb_zero_param = 0\n",
        "\n",
        "    layer_id = 0\n",
        "\n",
        "    for parameter in model.parameters():\n",
        "\n",
        "        param_this_layer = 1\n",
        "        for dim in parameter.data.size():\n",
        "            param_this_layer *= dim\n",
        "        total_nb_param += param_this_layer\n",
        "\n",
        "        # only pruning linear and conv layers\n",
        "        if len(parameter.data.size()) != 1:\n",
        "            layer_id += 1\n",
        "            zero_param_this_layer = np.count_nonzero(parameter.cpu().data.numpy() == 0)\n",
        "            nb_zero_param += zero_param_this_layer\n",
        "\n",
        "            if verbose:\n",
        "                print(\"Layer {} | {} layer | {:.2f}% parameters pruned\".format(\n",
        "                    layer_id,\n",
        "                    'Conv' if len(parameter.data.size()) == 4 \\\n",
        "                        else 'Linear',\n",
        "                    100. * zero_param_this_layer / param_this_layer,\n",
        "                ))\n",
        "    pruning_perc = 100. * nb_zero_param / total_nb_param\n",
        "    if verbose:\n",
        "        print(\"Final pruning rate: {:.2f}%\".format(pruning_perc))\n",
        "    return pruning_perc\n",
        "\n",
        "\n",
        "def arg_nonzero_min(a):\n",
        "    \"\"\"\n",
        "    nonzero argmin of a non-negative array\n",
        "    \"\"\"\n",
        "\n",
        "    if not a:\n",
        "      return\n",
        "\n",
        "    min_ix, min_v = None, None\n",
        "    # find the starting value (should be nonzero)\n",
        "    for i, e in enumerate(a):\n",
        "        if e != 0:\n",
        "            min_ix = i\n",
        "            min_v = e\n",
        "    if not min_ix:\n",
        "        print('Warning: all zero')\n",
        "        return np.inf, np.inf\n",
        "\n",
        "    # search for the smallest nonzero\n",
        "    for i, e in enumerate(a):\n",
        "        if e < min_v and e != 0:\n",
        "            min_v = e\n",
        "            min_ix = i\n",
        "\n",
        "    return min_v, min_ix\n",
        "\n",
        "\n",
        "def prune_one_filter(model, masks):\n",
        "    '''\n",
        "    Pruning one least ``important'' feature map by the scaled l2norm of\n",
        "    kernel weights\n",
        "    arXiv:1611.06440\n",
        "    '''\n",
        "    NO_MASKS = False\n",
        "    # construct masks if there is not yet\n",
        "    if not masks:\n",
        "        masks = []\n",
        "        NO_MASKS = True\n",
        "\n",
        "    values = []\n",
        "    for p in model.parameters():\n",
        "\n",
        "        if len(p.data.size()) == 4:  # nasty way of selecting conv layer\n",
        "            p_np = p.data.cpu().numpy()\n",
        "           \n",
        "\n",
        "            # construct masks if there is not\n",
        "            if NO_MASKS:\n",
        "                masks.append(np.ones(p_np.shape).astype('float32'))\n",
        "\n",
        "#            # find the scaled l2 norm for each filter this layer\n",
        "#            value_this_layer = np.square(p_np).sum(axis=1).sum(axis=1).sum(axis=1) / (\n",
        "#                    p_np.shape[1] * p_np.shape[2] * p_np.shape[3])\n",
        "#            # normalization (important)\n",
        "#           value_this_layer = value_this_layer / np.sqrt(np.square(value_this_layer).sum())\n",
        "            # 找到通道值的最小值以及索引\n",
        "            p_np = torch.from_numpy(p_np)\n",
        "            dims = list(range(1,p_np.dim()))\n",
        "            value_this_layer = torch.norm(p_np, p=1, dim=dims)/(p_np.shape[1] * p_np.shape[2] * p_np.shape[3])\n",
        "            value_this_layer = value_this_layer/ np.sqrt(np.square(value_this_layer).sum())\n",
        "            min_value, min_ind = arg_nonzero_min(list(value_this_layer.numpy()))\n",
        "            values.append([min_value, min_ind])\n",
        "            #print(value_this_layer)\n",
        "\n",
        "    assert len(masks) == len(values), \"something wrong here\"\n",
        "\n",
        "    values = np.array(values)\n",
        "\n",
        "    # set mask corresponding to the filter to prune\n",
        "    to_prune_layer_ind = np.argmin(values[:, 0])\n",
        "    to_prune_filter_ind = int(values[to_prune_layer_ind, 1])\n",
        "    masks[to_prune_layer_ind][to_prune_filter_ind] = 0.\n",
        "\n",
        "    #     print('Prune filter #{} in layer #{}'.format(\n",
        "    #         to_prune_filter_ind,\n",
        "    #         to_prune_layer_ind))\n",
        "\n",
        "    return masks\n",
        "\n",
        "\n",
        "def filter_prune(model, pruning_perc):\n",
        "    '''\n",
        "    Prune filters one by one until reach pruning_perc\n",
        "    (not iterative pruning)\n",
        "    '''\n",
        "    masks = []\n",
        "    current_pruning_perc = 0.\n",
        "\n",
        "    while current_pruning_perc < pruning_perc:\n",
        "        masks = prune_one_filter(model, masks)\n",
        "        model.set_masks(masks)\n",
        "        current_pruning_perc = prune_rate(model, verbose=False)\n",
        "    #         print('{:.2f} pruned'.format(current_pruning_perc))\n",
        "    return masks\n",
        "\n",
        "\n",
        "def plot_weights(model):\n",
        "    modules = [module for module in model.modules()]\n",
        "    num_sub_plot = 0\n",
        "    for i, layer in enumerate(modules):\n",
        "        print(i)\n",
        "        if hasattr(layer, 'weight'):\n",
        "            plt.subplot(131 + num_sub_plot)\n",
        "            w = layer.weight.data\n",
        "            w_one_dim = w.cpu().numpy().flatten()\n",
        "            plt.hist(w_one_dim[w_one_dim != 0], bins=50)\n",
        "            num_sub_plot += 1\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttlUZteVpEX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaskedConv2d(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
        "        super().__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
        "        self.mask_flag = False\n",
        "\n",
        "    def set_mask(self, mask):\n",
        "        self.mask = to_var(mask, requires_grad=False)\n",
        "        self.weight.data = self.weight.data * self.mask.data\n",
        "        self.mask_flag = True\n",
        "\n",
        "    def get_mask(self):\n",
        "        print(self.mask_flag)\n",
        "        return self.mask\n",
        "\n",
        "    def forward(self, data):\n",
        "        if self.mask_flag:\n",
        "            weight = self.weight * self.mask\n",
        "            return F.conv2d(data, weight, self.bias, self.stride,\n",
        "                            self.padding, self.dilation, self.groups)\n",
        "        else:\n",
        "            return F.conv2d(data, self.weight, self.bias, self.stride,\n",
        "                            self.padding, self.dilation, self.groups)\n",
        "\n",
        "\n",
        "class MaskedLinear(nn.Linear):\n",
        "    def __init__(self, in_channels, out_channels, bias=True):\n",
        "        super().__init__(in_channels, out_channels, bias)\n",
        "        self.mask_flag = False\n",
        "\n",
        "    def set_mask(self, mask):\n",
        "        self.mask = to_var(mask, requires_grad=False)\n",
        "        self.weight.data = self.weight.data * self.mask.data\n",
        "        self.mask_flag = True\n",
        "\n",
        "    def get_mask(self):\n",
        "        print(self.mask_flag)\n",
        "        return self.mask\n",
        "\n",
        "    def forward(self, data):\n",
        "        if self.mask_flag:\n",
        "            weight = self.weight * self.mask\n",
        "            return F.linear(data, weight, self.bias)\n",
        "        else:\n",
        "            return F.linear(data, self.weight, self.bias)\n",
        "\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = MaskedConv2d(1, 32, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.maxpool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = MaskedConv2d(32, 64, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.maxpool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv3 = MaskedConv2d(64, 64, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.linear1 = MaskedLinear(7 * 7 * 64, 128)\n",
        "        self.linear2 = MaskedLinear(128, 10)\n",
        "\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, data):\n",
        "        out = self.maxpool1(self.relu1(self.conv1(data)))\n",
        "        out = self.maxpool2(self.relu2(self.conv2(out)))\n",
        "        out = self.relu3(self.conv3(out))\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear1(out)\n",
        "        out = self.linear2(out)\n",
        "        return out\n",
        "\n",
        "    def get_loss(self, output, label):\n",
        "        return self.loss(output, label)\n",
        "\n",
        "    def set_masks(self, masks, isLinear=False):\n",
        "        # Should be a less manual way to set masks\n",
        "        # Leave it for the future\n",
        "        if isLinear:\n",
        "            self.linear1.set_mask(masks[0])\n",
        "            self.linear2.set_mask(masks[1])\n",
        "        else:\n",
        "            self.conv1.set_mask(torch.from_numpy(masks[0]))\n",
        "            self.conv2.set_mask(torch.from_numpy(masks[1]))\n",
        "            self.conv3.set_mask(torch.from_numpy(masks[2]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzpKGGa3rgwJ",
        "colab_type": "text"
      },
      "source": [
        "# 3 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BDmJwWpqUQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjtm4XJlvmas",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 数据准备"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjREf1gPAeMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#图像的预处理归一化[0,1],transforms.Normalize即image=(image-mean)/std到[-1,1]\n",
        "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
        "#加载训练集,不是独热编码\n",
        "train_data = DataLoader(datasets.FashionMNIST(\"./datasets/\", train=True, transform=trans, download=True),\n",
        "                              batch_size=100, shuffle=True, drop_last=True)\n",
        "#加载测试集\n",
        "test_data = DataLoader(datasets.FashionMNIST(\"./datasets/\", train=False, transform=trans, download=True),\n",
        "                               batch_size=100, shuffle=True, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXIYrT1HCWjB",
        "colab_type": "code",
        "outputId": "66f24465-5a81-46e6-fbd0-e40e580b416e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for X,y in train_data:\n",
        "    print(X.shape,y.shape)\n",
        "    break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLV-RbzxrBrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer:\n",
        "    def __init__(self, save_path):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.save_path = save_path\n",
        "        self.net = MyNet().to(self.device)\n",
        "        self.optimizer = torch.optim.Adam(self.net.parameters())\n",
        "        self.net.train()\n",
        "        \n",
        "    def evaluate_accuracy(self,test_data):\n",
        "        acc_sum, n = 0.0, 0\n",
        "        for X, y in test_data:\n",
        "            X, y = X.to(self.device), y.to(self.device)\n",
        "            if isinstance(self.net, torch.nn.Module):\n",
        "                self.net.eval() # 评估模式, 这会关闭dropout\n",
        "                acc_sum += (self.net(X).argmax(dim=1) == y).float().sum().item()\n",
        "                self.net.train() # 改回训练模式\n",
        "            else: # 自定义的模型\n",
        "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
        "                    # 将is_training设置成False\n",
        "                    acc_sum += (self.net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
        "                else:\n",
        "                    acc_sum += (self.net(X).argmax(dim=1) == y).float().sum().item() \n",
        "            n += y.shape[0]\n",
        "        return acc_sum / n\n",
        "\n",
        "    def train(self,train_data,test_data,epochs):\n",
        "        for epoch in range(1, epochs):\n",
        "            total = 0\n",
        "            train_acc_sum,train_l_sum,n,start = 0.0,0.0,0,time.time()\n",
        "            for i, (data, label) in enumerate(train_data):\n",
        "                data, label = data.to(self.device), label.to(self.device)\n",
        "                output = self.net(data)\n",
        "                loss = self.net.get_loss(output, label)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                total += len(data)\n",
        "                #训练损失\n",
        "                train_l_sum += loss.item()\n",
        "                train_acc_sum += ((output.argmax(dim=1)) == label).sum().item()\n",
        "                n += 100  \n",
        "                progress = math.ceil(i / len(train_data) * 50)\n",
        "                print(\"\\rTrain epoch %d: %d/%d, [%-51s] %d%%\" %\n",
        "                      (epoch, total, len(train_data.dataset),\n",
        "                       '-' * progress + '>', progress * 2), end='')\n",
        "            test_acc = self.evaluate_accuracy(test_data)\n",
        "            print(\"\\nepoch %d,loss %.4f, train_acc %.3f, test_acc %.3f,time %.1f sec\"\n",
        "              %(epoch,train_l_sum/n,train_acc_sum/n,test_acc,time.time()-start))\n",
        "              \n",
        "            torch.save(self.net.state_dict(), self.save_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knHAq-wjr6LB",
        "colab_type": "code",
        "outputId": "f23656f7-f0fc-442e-d06f-1ae0fa127017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    trainer = Trainer(\"./model/finsh_minst_net.pth\")\n",
        "    trainer.train(train_data,test_data,epochs=10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch 1: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 1,loss 0.0045, train_acc 0.839, test_acc 0.885,time 22.9 sec\n",
            "Train epoch 2: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 2,loss 0.0028, train_acc 0.898, test_acc 0.900,time 22.9 sec\n",
            "Train epoch 3: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 3,loss 0.0024, train_acc 0.912, test_acc 0.902,time 22.9 sec\n",
            "Train epoch 4: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 4,loss 0.0021, train_acc 0.923, test_acc 0.905,time 23.1 sec\n",
            "Train epoch 5: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 5,loss 0.0019, train_acc 0.932, test_acc 0.909,time 23.0 sec\n",
            "Train epoch 6: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 6,loss 0.0017, train_acc 0.938, test_acc 0.920,time 23.0 sec\n",
            "Train epoch 7: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 7,loss 0.0015, train_acc 0.945, test_acc 0.919,time 23.1 sec\n",
            "Train epoch 8: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 8,loss 0.0014, train_acc 0.948, test_acc 0.913,time 23.0 sec\n",
            "Train epoch 9: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 9,loss 0.0012, train_acc 0.954, test_acc 0.915,time 22.9 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUtS6IzAurI3",
        "colab_type": "text"
      },
      "source": [
        "# 4 对模型进行剪枝\n",
        "## 4.1 构建剪枝网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZTvoNfoWbjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e24c5da-a991-47e5-cca1-b9b73405e169"
      },
      "source": [
        "net = MyNet().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.load_state_dict(torch.load(\"./model/finsh_minst_net.pth\"))\n",
        "#剪枝\n",
        "prune_rate(net,verbose=True)\n",
        "for i in range(1,10):\n",
        "  mask = weight_prune(net,i*10)\n",
        "  net.set_masks(mask, isLinear=True)\n",
        "  _=filter_prune(net,i*10)\n",
        "  prune_rate(net,verbose=True)\n",
        "  amount = 0.1*i\n",
        "  torch.save(net.state_dict(), f\"./model/pruned_net_with_torch_{amount:.1f}_l1.pth\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 0.00% parameters pruned\n",
            "Layer 5 | Linear layer | 0.00% parameters pruned\n",
            "Final pruning rate: 0.00%\n",
            "Layer 1 | Conv layer | 9.38% parameters pruned\n",
            "Layer 2 | Conv layer | 9.38% parameters pruned\n",
            "Layer 3 | Conv layer | 10.94% parameters pruned\n",
            "Layer 4 | Linear layer | 10.02% parameters pruned\n",
            "Layer 5 | Linear layer | 3.59% parameters pruned\n",
            "Final pruning rate: 10.04%\n",
            "Layer 1 | Conv layer | 12.50% parameters pruned\n",
            "Layer 2 | Conv layer | 25.00% parameters pruned\n",
            "Layer 3 | Conv layer | 18.75% parameters pruned\n",
            "Layer 4 | Linear layer | 20.04% parameters pruned\n",
            "Layer 5 | Linear layer | 7.89% parameters pruned\n",
            "Final pruning rate: 20.08%\n",
            "Layer 1 | Conv layer | 18.75% parameters pruned\n",
            "Layer 2 | Conv layer | 37.50% parameters pruned\n",
            "Layer 3 | Conv layer | 28.12% parameters pruned\n",
            "Layer 4 | Linear layer | 30.06% parameters pruned\n",
            "Layer 5 | Linear layer | 12.34% parameters pruned\n",
            "Final pruning rate: 30.12%\n",
            "Layer 1 | Conv layer | 25.00% parameters pruned\n",
            "Layer 2 | Conv layer | 45.31% parameters pruned\n",
            "Layer 3 | Conv layer | 39.06% parameters pruned\n",
            "Layer 4 | Linear layer | 40.07% parameters pruned\n",
            "Layer 5 | Linear layer | 17.03% parameters pruned\n",
            "Final pruning rate: 40.10%\n",
            "Layer 1 | Conv layer | 28.12% parameters pruned\n",
            "Layer 2 | Conv layer | 54.69% parameters pruned\n",
            "Layer 3 | Conv layer | 48.44% parameters pruned\n",
            "Layer 4 | Linear layer | 50.09% parameters pruned\n",
            "Layer 5 | Linear layer | 22.89% parameters pruned\n",
            "Final pruning rate: 50.02%\n",
            "Layer 1 | Conv layer | 40.62% parameters pruned\n",
            "Layer 2 | Conv layer | 64.06% parameters pruned\n",
            "Layer 3 | Conv layer | 59.38% parameters pruned\n",
            "Layer 4 | Linear layer | 60.10% parameters pruned\n",
            "Layer 5 | Linear layer | 29.45% parameters pruned\n",
            "Final pruning rate: 60.06%\n",
            "Layer 1 | Conv layer | 53.12% parameters pruned\n",
            "Layer 2 | Conv layer | 73.44% parameters pruned\n",
            "Layer 3 | Conv layer | 70.31% parameters pruned\n",
            "Layer 4 | Linear layer | 70.10% parameters pruned\n",
            "Layer 5 | Linear layer | 37.34% parameters pruned\n",
            "Final pruning rate: 70.11%\n",
            "Layer 1 | Conv layer | 65.62% parameters pruned\n",
            "Layer 2 | Conv layer | 82.81% parameters pruned\n",
            "Layer 3 | Conv layer | 79.69% parameters pruned\n",
            "Layer 4 | Linear layer | 80.11% parameters pruned\n",
            "Layer 5 | Linear layer | 46.41% parameters pruned\n",
            "Final pruning rate: 80.03%\n",
            "Layer 1 | Conv layer | 84.38% parameters pruned\n",
            "Layer 2 | Conv layer | 90.62% parameters pruned\n",
            "Layer 3 | Conv layer | 90.62% parameters pruned\n",
            "Layer 4 | Linear layer | 90.09% parameters pruned\n",
            "Layer 5 | Linear layer | 61.48% parameters pruned\n",
            "Final pruning rate: 90.01%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJpDAQm5BHpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d6a61bd-30d8-4b46-f676-f4b05ad828b0"
      },
      "source": [
        "net = MyNet().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.load_state_dict(torch.load(\"./model/finsh_minst_net.pth\"))\n",
        "#剪枝\n",
        "prune_rate(net,verbose=True)\n",
        "for i in range(1,10):\n",
        "  mask = weight_prune(net,i*10)\n",
        "  net.set_masks(mask, isLinear=True)\n",
        "  _=filter_prune(net,i*0)\n",
        "  prune_rate(net,verbose=True)\n",
        "  amount = 0.1*i\n",
        "  torch.save(net.state_dict(), f\"./model/pruned_net_with_torch_{amount:.1f}_weight_l1.pth\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 0.00% parameters pruned\n",
            "Layer 5 | Linear layer | 0.00% parameters pruned\n",
            "Final pruning rate: 0.00%\n",
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 10.02% parameters pruned\n",
            "Layer 5 | Linear layer | 3.59% parameters pruned\n",
            "Final pruning rate: 8.78%\n",
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 20.04% parameters pruned\n",
            "Layer 5 | Linear layer | 7.89% parameters pruned\n",
            "Final pruning rate: 17.56%\n",
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 30.06% parameters pruned\n",
            "Layer 5 | Linear layer | 12.34% parameters pruned\n",
            "Final pruning rate: 26.34%\n",
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 40.07% parameters pruned\n",
            "Layer 5 | Linear layer | 17.03% parameters pruned\n",
            "Final pruning rate: 35.13%\n",
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 50.09% parameters pruned\n",
            "Layer 5 | Linear layer | 22.89% parameters pruned\n",
            "Final pruning rate: 43.91%\n",
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 60.10% parameters pruned\n",
            "Layer 5 | Linear layer | 29.45% parameters pruned\n",
            "Final pruning rate: 52.69%\n",
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 70.10% parameters pruned\n",
            "Layer 5 | Linear layer | 37.34% parameters pruned\n",
            "Final pruning rate: 61.47%\n",
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 80.11% parameters pruned\n",
            "Layer 5 | Linear layer | 46.41% parameters pruned\n",
            "Final pruning rate: 70.25%\n",
            "Layer 1 | Conv layer | 0.00% parameters pruned\n",
            "Layer 2 | Conv layer | 0.00% parameters pruned\n",
            "Layer 3 | Conv layer | 0.00% parameters pruned\n",
            "Layer 4 | Linear layer | 90.09% parameters pruned\n",
            "Layer 5 | Linear layer | 61.48% parameters pruned\n",
            "Final pruning rate: 79.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wy---fAeZZE",
        "colab_type": "text"
      },
      "source": [
        "# 5 检测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj5U7mqevzsQ",
        "colab_type": "code",
        "outputId": "e4f06dd1-9e79-41d1-9b5b-879d83aac2ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "class Detector:\n",
        "    def __init__(self, net_path):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.net = MyNet().to(self.device)\n",
        "        self.map_location = None if torch.cuda.is_available() else lambda storage, loc: storage\n",
        "        self.net.load_state_dict(torch.load(net_path, map_location=self.map_location))\n",
        "        self.net.eval()\n",
        "\n",
        "    def detect(self,test_data):\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            for data, label in test_data:\n",
        "                data, label = data.to(self.device), label.to(self.device)\n",
        "                output = self.net(data)\n",
        "                test_loss += self.net.get_loss(output, label)\n",
        "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "                correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "\n",
        "        end = time.time()\n",
        "        print(f\"total time:{end - start}\")\n",
        "        test_loss /= len(test_data.dataset)\n",
        "\n",
        "        print('Test: average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_data.dataset),\n",
        "            100. * correct / len(test_data.dataset)))\n",
        "        #返回的损失和正确率\n",
        "        return [test_loss,correct/len(test_data.dataset)]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"./model/finsh_minst_net.pth\")\n",
        "    test_loss,accuracy,Parameter_compression_ratio = [],[],[]\n",
        "    detector1 = Detector(\"./model/finsh_minst_net.pth\")\n",
        "    loss,acc = detector1.detect(test_data)\n",
        "\n",
        "    test_loss.append(loss)\n",
        "    accuracy.append(acc)   \n",
        "    Parameter_compression_ratio.append(0)\n",
        "     \n",
        "    for i in range(1, 10):\n",
        "        amount = 0.1 * i\n",
        "        print(f\"./model/pruned_net_with_torch_{amount:.1f}_l1.pth\")\n",
        "        detector1 = Detector(f\"./model/pruned_net_with_torch_{amount:.1f}_l1.pth\")\n",
        "        loss,acc = detector1.detect(test_data)\n",
        "\n",
        "        test_loss.append(loss)\n",
        "        accuracy.append(acc)   \n",
        "        Parameter_compression_ratio.append(amount)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./model/finsh_minst_net.pth\n",
            "total time:2.36423397064209\n",
            "Test: average loss: 0.0025, accuracy: 9155/10000 (92%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.1_l1.pth\n",
            "total time:2.34464693069458\n",
            "Test: average loss: 0.0027, accuracy: 9067/10000 (91%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.2_l1.pth\n",
            "total time:2.3698177337646484\n",
            "Test: average loss: 0.0029, accuracy: 8995/10000 (90%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.3_l1.pth\n",
            "total time:2.369694471359253\n",
            "Test: average loss: 0.0034, accuracy: 8834/10000 (88%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.4_l1.pth\n",
            "total time:2.4069736003875732\n",
            "Test: average loss: 0.0043, accuracy: 8621/10000 (86%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.5_l1.pth\n",
            "total time:2.3909096717834473\n",
            "Test: average loss: 0.0089, accuracy: 6789/10000 (68%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.6_l1.pth\n",
            "total time:2.366197109222412\n",
            "Test: average loss: 0.0138, accuracy: 4626/10000 (46%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.7_l1.pth\n",
            "total time:2.374626874923706\n",
            "Test: average loss: 0.0211, accuracy: 2676/10000 (27%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.8_l1.pth\n",
            "total time:2.376844882965088\n",
            "Test: average loss: 0.0246, accuracy: 2062/10000 (21%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.9_l1.pth\n",
            "total time:2.387390375137329\n",
            "Test: average loss: 0.0271, accuracy: 1001/10000 (10%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A4-etR6Mn4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "4c88fdd6-dbaa-4c4a-ea04-995c68ca0746"
      },
      "source": [
        "class Detector:\n",
        "    def __init__(self, net_path):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.net = MyNet().to(self.device)\n",
        "        self.map_location = None if torch.cuda.is_available() else lambda storage, loc: storage\n",
        "        self.net.load_state_dict(torch.load(net_path, map_location=self.map_location))\n",
        "        self.net.eval()\n",
        "\n",
        "    def detect(self,test_data):\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            for data, label in test_data:\n",
        "                data, label = data.to(self.device), label.to(self.device)\n",
        "                output = self.net(data)\n",
        "                test_loss += self.net.get_loss(output, label)\n",
        "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "                correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "\n",
        "        end = time.time()\n",
        "        print(f\"total time:{end - start}\")\n",
        "        test_loss /= len(test_data.dataset)\n",
        "\n",
        "        print('Test: average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_data.dataset),\n",
        "            100. * correct / len(test_data.dataset)))\n",
        "        #返回的损失和正确率\n",
        "        return [test_loss,correct/len(test_data.dataset)]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"./model/finsh_minst_net.pth\")\n",
        "    test_loss_w,accuracy_w,Parameter_compression_ratio_w = [],[],[]\n",
        "    detector1 = Detector(\"./model/finsh_minst_net.pth\")\n",
        "    loss,acc = detector1.detect(test_data)\n",
        "\n",
        "    test_loss_w.append(loss)\n",
        "    accuracy_w.append(acc)   \n",
        "    Parameter_compression_ratio_w.append(0)\n",
        "     \n",
        "    for i in range(1, 10):\n",
        "        amount = 0.1 * i\n",
        "        print(f\"./model/pruned_net_with_torch_{amount:.1f}_l1.pth\")\n",
        "        detector1 = Detector(f\"./model/pruned_net_with_torch_{amount:.1f}_weight_l1.pth\")\n",
        "        loss,acc = detector1.detect(test_data)\n",
        "\n",
        "        test_loss_w.append(loss)\n",
        "        accuracy_w.append(acc)   \n",
        "        Parameter_compression_ratio_w.append(amount)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./model/finsh_minst_net.pth\n",
            "total time:2.416531801223755\n",
            "Test: average loss: 0.0025, accuracy: 9155/10000 (92%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.1_l1.pth\n",
            "total time:2.4031946659088135\n",
            "Test: average loss: 0.0025, accuracy: 9155/10000 (92%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.2_l1.pth\n",
            "total time:2.3649911880493164\n",
            "Test: average loss: 0.0025, accuracy: 9149/10000 (91%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.3_l1.pth\n",
            "total time:2.409180164337158\n",
            "Test: average loss: 0.0025, accuracy: 9150/10000 (92%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.4_l1.pth\n",
            "total time:2.3315677642822266\n",
            "Test: average loss: 0.0025, accuracy: 9155/10000 (92%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.5_l1.pth\n",
            "total time:2.380612373352051\n",
            "Test: average loss: 0.0025, accuracy: 9152/10000 (92%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.6_l1.pth\n",
            "total time:2.3330729007720947\n",
            "Test: average loss: 0.0024, accuracy: 9163/10000 (92%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.7_l1.pth\n",
            "total time:2.2958364486694336\n",
            "Test: average loss: 0.0024, accuracy: 9154/10000 (92%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.8_l1.pth\n",
            "total time:2.2687129974365234\n",
            "Test: average loss: 0.0025, accuracy: 9114/10000 (91%)\n",
            "\n",
            "./model/pruned_net_with_torch_0.9_l1.pth\n",
            "total time:2.3670296669006348\n",
            "Test: average loss: 0.0039, accuracy: 8861/10000 (89%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POq7EzYuHqh3",
        "colab_type": "code",
        "outputId": "9931791b-8d1f-4b36-f4bf-20a4d42b3a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig,ax = plt.subplots(1,2,figsize=(9,5))\n",
        "ax1 = plt.subplot(121)  #绘制子图1对象\n",
        "ax2 = plt.subplot(122)  #绘制子图2对象\n",
        "\n",
        "\n",
        "\n",
        "x = Parameter_compression_ratio\n",
        "y = accuracy\n",
        "y_w = accuracy_w\n",
        "y2 = test_loss\n",
        "y2_w = test_loss_w\n",
        "\n",
        "ax1.plot(x,y,color='red',label='accuracy')\n",
        "ax1.plot(x,y_w,color='blue',label='weight_accuracy')\n",
        "ax2.plot(x,y2,color='red',label='test_loss')\n",
        "ax2.plot(x,y2_w,color='blue',label='weight_test_loss')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0zAnBxJMbnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}