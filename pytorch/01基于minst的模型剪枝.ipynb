{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "基于minst的模型剪枝.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPr0VVU1PNZsenxlU0JOWbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaaili/test/blob/master/pytorch/01%E5%9F%BA%E4%BA%8Eminst%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSf-lzyUuCzz",
        "colab_type": "code",
        "outputId": "3d4fd6f1-61ed-480d-be8f-0fd2f58eec97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# 导入相关包\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/pytorch深度学习\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARQLeaxVuFSZ",
        "colab_type": "code",
        "outputId": "1e0b3fc7-a3be-4baa-e0cd-8978473b8f1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "print(torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utoZiP9En9cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#复制一个与x相同的mask\n",
        "def to_var(x, requires_grad=False):\n",
        "    \"\"\"\n",
        "    Automatically choose cpu or cuda\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return x.clone().detach().requires_grad_(requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x5Gfc79odoB",
        "colab_type": "text"
      },
      "source": [
        "# 2 构建网络"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2MXT3J4omt2",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 定义卷积层"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MA0msLXn2Eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#定义卷积层\n",
        "class MaskedConv2d(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
        "        super().__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
        "        self.mask_flag = False\n",
        "\n",
        "    def set_mask(self, mask):\n",
        "        self.mask = to_var(mask, requires_grad=False)\n",
        "        self.weight.data = self.weight.data * self.mask.data\n",
        "        self.mask_flag = True\n",
        "\n",
        "    def get_mask(self):\n",
        "        print(self.mask_flag)\n",
        "        return self.mask\n",
        "\n",
        "    def forward(self, data):\n",
        "        if self.mask_flag:\n",
        "            weight = self.weight * self.mask\n",
        "            return F.conv2d(data, weight, self.bias, self.stride,\n",
        "                            self.padding, self.dilation, self.groups)\n",
        "        else:\n",
        "            return F.conv2d(data, self.weight, self.bias, self.stride,\n",
        "                            self.padding, self.dilation, self.groups)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQQl4qtMou5-",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 构建全连接层"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkTDhRfkoV1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaskedLinear(nn.Linear):\n",
        "    def __init__(self, in_channels, out_channels, bias=True):\n",
        "        super().__init__(in_channels, out_channels, bias)\n",
        "        self.mask_flag = False\n",
        "\n",
        "    def set_mask(self, mask):\n",
        "        self.mask = to_var(mask, requires_grad=False)\n",
        "        self.weight.data = self.weight.data * self.mask.data\n",
        "        self.mask_flag = True\n",
        "\n",
        "    def get_mask(self):\n",
        "        print(self.mask_flag)\n",
        "        return self.mask\n",
        "\n",
        "    def forward(self, data):\n",
        "        if self.mask_flag:\n",
        "            weight = self.weight * self.mask\n",
        "            return F.linear(data, weight, self.bias)\n",
        "        else:\n",
        "            return F.linear(data, self.weight, self.bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKfyjmPfo_iI",
        "colab_type": "text"
      },
      "source": [
        "### 2.3定义网络结构\n",
        "这个网络有三个卷积层，两个全连接层组成，最后输出的是10分分类"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttlUZteVpEX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = MaskedConv2d(1, 32, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.maxpool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = MaskedConv2d(32, 64, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.maxpool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv3 = MaskedConv2d(64, 64, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.linear1 = MaskedLinear(7 * 7 * 64, 128)\n",
        "        self.linear2 = MaskedLinear(128, 10)\n",
        "\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, data):\n",
        "        out = self.maxpool1(self.relu1(self.conv1(data)))\n",
        "        out = self.maxpool2(self.relu2(self.conv2(out)))\n",
        "        out = self.relu3(self.conv3(out))\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear1(out)\n",
        "        out = self.linear2(out)\n",
        "        return out\n",
        "\n",
        "    def get_loss(self, output, label):\n",
        "        return self.loss(output, label)\n",
        "\n",
        "    def set_masks(self, masks, isLinear=False):\n",
        "        # Should be a less manual way to set masks\n",
        "        # Leave it for the future\n",
        "        if isLinear:\n",
        "            self.linear1.set_mask(masks[0])\n",
        "            self.linear2.set_mask(masks[1])\n",
        "        else:\n",
        "            self.conv1.set_mask(torch.from_numpy(masks[0]))\n",
        "            self.conv2.set_mask(torch.from_numpy(masks[1]))\n",
        "            self.conv3.set_mask(torch.from_numpy(masks[2]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8zqCn1WqItK",
        "colab_type": "code",
        "outputId": "e8c8f9f9-c82c-4fe7-8a7c-4159eb04ec32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    net = MyNet()\n",
        "    for p in net.conv1.parameters():\n",
        "        print(p.data.size())\n",
        "    for p in net.linear1.parameters():\n",
        "        print(p.data.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1, 3, 3])\n",
            "torch.Size([32])\n",
            "torch.Size([128, 3136])\n",
            "torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDZyiI-BpJt7",
        "colab_type": "code",
        "outputId": "2ada0598-de8a-46bb-b57e-40da0b0a909c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total = sum([param.nelement() for param in net.parameters()])\n",
        "print('  + Number of params: %.2fM' % (total / 1e6))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  + Number of params: 0.46M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzpKGGa3rgwJ",
        "colab_type": "text"
      },
      "source": [
        "# 3 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BDmJwWpqUQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjtm4XJlvmas",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 数据准备"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLV-RbzxrBrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer:\n",
        "    def __init__(self, save_path):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.save_path = save_path\n",
        "        self.net = MyNet().to(self.device)\n",
        "        self.trans = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5], [0.5])\n",
        "        ])\n",
        "        #加载训练集,不是独热编码\n",
        "        self.train_data = DataLoader(datasets.MNIST(\"./datasets/\", train=True, transform=self.trans, download=True),\n",
        "                                     batch_size=100, shuffle=True, drop_last=True)\n",
        "        #加载测试集\n",
        "        self.test_data = DataLoader(datasets.MNIST(\"./datasets/\", train=False, transform=self.trans, download=True),\n",
        "                                     batch_size=100, shuffle=True, drop_last=True)\n",
        "        self.optimizer = torch.optim.Adam(self.net.parameters())\n",
        "        self.net.train()\n",
        "        \n",
        "    def evaluate_accuracy(self,data_iter):\n",
        "        acc_sum, n = 0.0, 0\n",
        "        for X, y in data_iter:\n",
        "            X, y = X.to(self.device), y.to(self.device)\n",
        "            if isinstance(self.net, torch.nn.Module):\n",
        "                net.eval() # 评估模式, 这会关闭dropout\n",
        "                acc_sum += (self.net(X).argmax(dim=1) == y).float().sum().item()\n",
        "                net.train() # 改回训练模式\n",
        "            else: # 自定义的模型\n",
        "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
        "                    # 将is_training设置成False\n",
        "                    acc_sum += (self.net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
        "                else:\n",
        "                    acc_sum += (self.net(X).argmax(dim=1) == y).float().sum().item() \n",
        "            n += y.shape[0]\n",
        "        return acc_sum / n\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(1, 5):\n",
        "            total = 0\n",
        "            train_acc_sum,train_l_sum,n,start = 0.0,0.0,0,time.time()\n",
        "            for i, (data, label) in enumerate(self.train_data):\n",
        "                data, label = data.to(self.device), label.to(self.device)\n",
        "                output = self.net(data)\n",
        "                loss = self.net.get_loss(output, label)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                total += len(data)\n",
        "                #训练损失\n",
        "                train_l_sum += loss.item()\n",
        "                train_acc_sum += ((output.argmax(dim=1)) == label).sum().item()\n",
        "                n += 100  \n",
        "                progress = math.ceil(i / len(self.train_data) * 50)\n",
        "                print(\"\\rTrain epoch %d: %d/%d, [%-51s] %d%%\" %\n",
        "                      (epoch, total, len(self.train_data.dataset),\n",
        "                       '-' * progress + '>', progress * 2), end='')\n",
        "            test_acc = self.evaluate_accuracy(self.test_data)\n",
        "            print(\"\\nepoch %d,loss %.4f, train_acc %.3f, test_acc %.3f,time %.1f sec\"\n",
        "              %(epoch+1,train_l_sum/n,train_acc_sum/n,test_acc,time.time()-start))\n",
        "              \n",
        "            torch.save(self.net.state_dict(), self.save_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knHAq-wjr6LB",
        "colab_type": "code",
        "outputId": "afa4d949-37ac-4181-8eeb-f4fabea81392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    trainer = Trainer(\"./net.pth\")\n",
        "    trainer.train()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch 1: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 2,loss 0.0015, train_acc 0.954, test_acc 0.986,time 11.5 sec\n",
            "Train epoch 2: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 3,loss 0.0004, train_acc 0.987, test_acc 0.991,time 11.2 sec\n",
            "Train epoch 3: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 4,loss 0.0003, train_acc 0.990, test_acc 0.988,time 11.2 sec\n",
            "Train epoch 4: 60000/60000, [-------------------------------------------------->] 100%\n",
            "epoch 5,loss 0.0002, train_acc 0.992, test_acc 0.992,time 11.4 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUtS6IzAurI3",
        "colab_type": "text"
      },
      "source": [
        "# 4 对模型进行剪枝\n",
        "## 4.1 构建剪枝网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR_HKGeCzfhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "b0c04116-eaa2-4aac-f01e-0fe32b1d6281"
      },
      "source": [
        "import torch\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "\n",
        "class Pruning:\n",
        "    #net_path是修建的模型，amount是模型的修建率\n",
        "    def __init__(self, net_path, amount):\n",
        "        self.net = MyNet()\n",
        "        #加载模型\n",
        "        self.net.load_state_dict(torch.load(net_path))\n",
        "        #将模型都定义为元组,这是全局修剪的方法\n",
        "        self.parameters_to_prune = (\n",
        "            (self.net.conv1, 'weight'),\n",
        "            (self.net.conv2, 'weight'),\n",
        "            (self.net.conv3, 'weight'),\n",
        "            (self.net.linear1, 'weight'),\n",
        "            (self.net.linear2, 'weight'),\n",
        "        )\n",
        "        self.amount = amount\n",
        "\n",
        "    def pruning(self):\n",
        "      #全局修剪参数，方法是修剪绝对值参数\n",
        "        prune.global_unstructured(\n",
        "            self.parameters_to_prune,\n",
        "            pruning_method=prune.L1Unstructured,\n",
        "            amount=self.amount,\n",
        "        )\n",
        "        # print(self.net.state_dict().keys())\n",
        "        # 删除weight_orig 、weight_mask以及forward_pre_hook\n",
        "        prune.remove(self.net.conv1, 'weight')\n",
        "        prune.remove(self.net.conv2, 'weight')\n",
        "        prune.remove(self.net.conv3, 'weight')\n",
        "        prune.remove(self.net.linear1, 'weight')\n",
        "        prune.remove(self.net.linear2, 'weight')\n",
        "        # print(self.net.linear1.weight)\n",
        "        # mask = weight_prune(self.net, 60)\n",
        "        # self.net.set_masks(mask, True)\n",
        "        # torch.save(self.net.state_dict(), \"self.nets/pruned_net_without_conv.pth\")\n",
        "        # filter_prune(self.net, 50)\n",
        "        print(\n",
        "            \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
        "                100. * float(torch.sum(self.net.conv1.weight == 0))\n",
        "                / float(self.net.conv1.weight.nelement())\n",
        "            )\n",
        "        )\n",
        "        print(\n",
        "            \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
        "                100. * float(torch.sum(self.net.conv2.weight == 0))\n",
        "                / float(self.net.conv2.weight.nelement())\n",
        "            )\n",
        "        )\n",
        "        print(\n",
        "            \"Sparsity in conv3.weight: {:.2f}%\".format(\n",
        "                100. * float(torch.sum(self.net.conv3.weight == 0))\n",
        "                / float(self.net.conv3.weight.nelement())\n",
        "            )\n",
        "        )\n",
        "        print(\n",
        "            \"Sparsity in linear1.weight: {:.2f}%\".format(\n",
        "                100. * float(torch.sum(self.net.linear1.weight == 0))\n",
        "                / float(self.net.linear1.weight.nelement())\n",
        "            )\n",
        "        )\n",
        "        print(\n",
        "            \"Sparsity in linear2.weight: {:.2f}%\".format(\n",
        "                100. * float(torch.sum(self.net.linear2.weight == 0))\n",
        "                / float(self.net.linear2.weight.nelement())\n",
        "            )\n",
        "        )\n",
        "        print(\n",
        "            \"Global sparsity: {:.2f}%\".format(\n",
        "                100. * float(\n",
        "                    torch.sum(self.net.conv1.weight == 0)\n",
        "                    + torch.sum(self.net.conv2.weight == 0)\n",
        "                    + torch.sum(self.net.conv3.weight == 0)\n",
        "                    + torch.sum(self.net.linear1.weight == 0)\n",
        "                    + torch.sum(self.net.linear2.weight == 0)\n",
        "                )\n",
        "                / float(\n",
        "                    self.net.conv1.weight.nelement()\n",
        "                    + self.net.conv2.weight.nelement()\n",
        "                    + self.net.conv3.weight.nelement()\n",
        "                    + self.net.linear1.weight.nelement()\n",
        "                    + self.net.linear2.weight.nelement()\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        # torch.save(self.net.state_dict(), \"models/pruned_net_with_conv.pth\")\n",
        "        torch.save(self.net.state_dict(), f\"./pruned_net_with_torch_{self.amount:.1f}_l1.pth\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    for i in range(1, 10):\n",
        "        pruning = Pruning(\"./net.pth\", 0.1 * i)\n",
        "        pruning.pruning()\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity in conv1.weight: 0.35%\n",
            "Sparsity in conv2.weight: 4.50%\n",
            "Sparsity in conv3.weight: 6.08%\n",
            "Sparsity in linear1.weight: 10.64%\n",
            "Sparsity in linear2.weight: 4.06%\n",
            "Global sparsity: 10.00%\n",
            "Sparsity in conv1.weight: 0.69%\n",
            "Sparsity in conv2.weight: 9.61%\n",
            "Sparsity in conv3.weight: 12.47%\n",
            "Sparsity in linear1.weight: 21.22%\n",
            "Sparsity in linear2.weight: 7.03%\n",
            "Global sparsity: 20.00%\n",
            "Sparsity in conv1.weight: 2.08%\n",
            "Sparsity in conv2.weight: 14.75%\n",
            "Sparsity in conv3.weight: 19.11%\n",
            "Sparsity in linear1.weight: 31.78%\n",
            "Sparsity in linear2.weight: 10.55%\n",
            "Global sparsity: 30.00%\n",
            "Sparsity in conv1.weight: 3.12%\n",
            "Sparsity in conv2.weight: 20.15%\n",
            "Sparsity in conv3.weight: 25.90%\n",
            "Sparsity in linear1.weight: 42.32%\n",
            "Sparsity in linear2.weight: 13.44%\n",
            "Global sparsity: 40.00%\n",
            "Sparsity in conv1.weight: 4.51%\n",
            "Sparsity in conv2.weight: 26.18%\n",
            "Sparsity in conv3.weight: 33.31%\n",
            "Sparsity in linear1.weight: 52.76%\n",
            "Sparsity in linear2.weight: 17.58%\n",
            "Global sparsity: 50.00%\n",
            "Sparsity in conv1.weight: 6.94%\n",
            "Sparsity in conv2.weight: 33.33%\n",
            "Sparsity in conv3.weight: 41.82%\n",
            "Sparsity in linear1.weight: 63.05%\n",
            "Sparsity in linear2.weight: 21.56%\n",
            "Global sparsity: 60.00%\n",
            "Sparsity in conv1.weight: 8.68%\n",
            "Sparsity in conv2.weight: 41.76%\n",
            "Sparsity in conv3.weight: 51.54%\n",
            "Sparsity in linear1.weight: 73.17%\n",
            "Sparsity in linear2.weight: 26.64%\n",
            "Global sparsity: 70.00%\n",
            "Sparsity in conv1.weight: 12.85%\n",
            "Sparsity in conv2.weight: 52.66%\n",
            "Sparsity in conv3.weight: 63.72%\n",
            "Sparsity in linear1.weight: 82.94%\n",
            "Sparsity in linear2.weight: 34.77%\n",
            "Global sparsity: 80.00%\n",
            "Sparsity in conv1.weight: 15.28%\n",
            "Sparsity in conv2.weight: 68.71%\n",
            "Sparsity in conv3.weight: 78.72%\n",
            "Sparsity in linear1.weight: 92.20%\n",
            "Sparsity in linear2.weight: 49.06%\n",
            "Global sparsity: 90.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wy---fAeZZE",
        "colab_type": "text"
      },
      "source": [
        "# 5 检测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj5U7mqevzsQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "ee18c7f0-b132-453c-9d0c-9d630349071b"
      },
      "source": [
        "class Detector:\n",
        "    def __init__(self, net_path):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.net = MyNet().to(self.device)\n",
        "        self.trans = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5], [0.5])\n",
        "        ])\n",
        "        self.test_data = DataLoader(datasets.MNIST(\"../datasets/\", train=False, transform=self.trans, download=False),\n",
        "                                    batch_size=100, shuffle=True, drop_last=True)\n",
        "        # 如果没有GPU的话把在GPU上训练的参数放在CPU上运行，cpu-->gpu 1:lambda storage, loc: storage.cuda(1)\n",
        "        self.map_location = None if torch.cuda.is_available() else lambda storage, loc: storage\n",
        "        self.net.load_state_dict(torch.load(net_path, map_location=self.map_location))\n",
        "        self.net.eval()\n",
        "\n",
        "    def detect(self):\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            for data, label in self.test_data:\n",
        "                data, label = data.to(self.device), label.to(self.device)\n",
        "                output = self.net(data)\n",
        "                test_loss += self.net.get_loss(output, label)\n",
        "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "                correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "\n",
        "        end = time.time()\n",
        "        print(f\"total time:{end - start}\")\n",
        "        test_loss /= len(self.test_data.dataset)\n",
        "\n",
        "        print('Test: average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(self.test_data.dataset),\n",
        "            100. * correct / len(self.test_data.dataset)))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"./net.pth\")\n",
        "    detector1 = Detector(\"./net.pth\")\n",
        "    detector1.detect()\n",
        "\n",
        "    for i in range(1, 10):\n",
        "        amount = 0.1 * i\n",
        "        print(f\"./pruned_net_with_torch_{amount:.1f}_l1.pth\")\n",
        "        detector1 = Detector(f\"./pruned_net_with_torch_{amount:.1f}_l1.pth\")\n",
        "        detector1.detect()\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./net.pth\n",
            "total time:1.4062409400939941\n",
            "Test: average loss: 0.0003, accuracy: 9915/10000 (99%)\n",
            "\n",
            "./pruned_net_with_torch_0.1_l1.pth\n",
            "total time:1.404999017715454\n",
            "Test: average loss: 0.0003, accuracy: 9915/10000 (99%)\n",
            "\n",
            "./pruned_net_with_torch_0.2_l1.pth\n",
            "total time:1.3932301998138428\n",
            "Test: average loss: 0.0003, accuracy: 9916/10000 (99%)\n",
            "\n",
            "./pruned_net_with_torch_0.3_l1.pth\n",
            "total time:1.404151439666748\n",
            "Test: average loss: 0.0003, accuracy: 9918/10000 (99%)\n",
            "\n",
            "./pruned_net_with_torch_0.4_l1.pth\n",
            "total time:1.3637206554412842\n",
            "Test: average loss: 0.0003, accuracy: 9915/10000 (99%)\n",
            "\n",
            "./pruned_net_with_torch_0.5_l1.pth\n",
            "total time:1.3584282398223877\n",
            "Test: average loss: 0.0003, accuracy: 9912/10000 (99%)\n",
            "\n",
            "./pruned_net_with_torch_0.6_l1.pth\n",
            "total time:1.3912827968597412\n",
            "Test: average loss: 0.0003, accuracy: 9906/10000 (99%)\n",
            "\n",
            "./pruned_net_with_torch_0.7_l1.pth\n",
            "total time:1.3662254810333252\n",
            "Test: average loss: 0.0003, accuracy: 9907/10000 (99%)\n",
            "\n",
            "./pruned_net_with_torch_0.8_l1.pth\n",
            "total time:1.3926959037780762\n",
            "Test: average loss: 0.0005, accuracy: 9894/10000 (99%)\n",
            "\n",
            "./pruned_net_with_torch_0.9_l1.pth\n",
            "total time:1.3720574378967285\n",
            "Test: average loss: 0.0037, accuracy: 9801/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5i4X9c2wUPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module = model.conv1\n",
        "print(list(module.named_parameters()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}